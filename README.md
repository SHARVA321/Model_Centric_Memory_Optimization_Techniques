# Embedded ML Memory Optimization Techniques

A side-by-side evaluation of systemâ€level and modelâ€centric memoryâ€optimization techniques for realâ€‘time human activity recognition (HAR) on resourceâ€‘constrained edge platforms, using the WISDM dataset. This project reâ€‘implements and compares five embeddedâ€‘inspired optimizations and four MLâ€‘centric methods, culminating in a hybrid pipeline that balances memory footprint, inference latency, and predictive accuracy.

---

## ğŸ“‹ Table of Contents

- [ğŸš€ Project Overview](#-project-overview)  
- [ğŸ”§ Features](#-features)  
- [âš™ï¸ Getting Started](#ï¸-getting-started)  
  - [Prerequisites](#prerequisites)  
  - [Installation](#installation)  
- [ğŸ—‚ Repository Structure](#-repository-structure)  
- [ğŸ›  Implemented Techniques](#-implemented-techniques)  
  - [Systemâ€‘Level Optimizations](#systemâ€‘level-optimizations)  
  - [Modelâ€‘Centric Methods](#modelâ€‘centric-methods)  
  - [Hybrid Pipeline](#hybrid-pipeline)  
- [ğŸ§ª Experimental Setup](#-experimental-setup)  
- [ğŸ“ˆ Results & Evaluation](#-results--evaluation)  
- [ğŸ¤ Contributing](#-contributing)  
- [ğŸ“„ License](#-license)  
- [ğŸ“š References](#-references)  

---

## ğŸš€ Project Overview

Edge and IoT devices often have stringent constraints on memory (â‰¤4â€¯MB), compute (â‰¤200â€¯MHz), and power (â‰¤50â€¯mW), making deployment of modern ML models challenging. This repo implements:

1. **Systemâ€‘level code optimizations** (static memory pruning, codeâ€‘hierarchy flattening, lazy loading, etc.)  
2. **Modelâ€‘centric methods** (int8 quantization, structured pruning, dynamic loading, PCA, contrastive encoding)  
3. **A hybrid pipeline** combining both approaches for the best tradeâ€‘off between resource efficiency and accuracy.

---

## ğŸ”§ Features

- ğŸš€ Ultraâ€‘low memory footprint (down to 0.08â€¯MB)  
- âš¡ Realâ€‘time inference latency (as low as 0.03â€¯s)  
- ğŸ“Š High HAR accuracy (up to 93.7â€¯%)  
- ğŸ”„ Modular pipelines for easy swapping of optimization techniques  
- ğŸ“‘ Automated scripts for reproducible experiments  

---

## âš™ï¸ Getting Started

### Prerequisites

- PythonÂ 3.12  
- PyTorchÂ 2.x  
- scikitâ€‘learn  
- numpy, pandas, matplotlib  


```bash
# Clone the repo
git clone https://github.com/yourusername/embedded-ml-memory-optimization.git
cd embedded-ml-memory-optimization

# Create a virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
